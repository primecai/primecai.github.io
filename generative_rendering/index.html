<!DOCTYPE html>

<head>
    <meta charset="utf-8">
    <title>Generative Rendering</title>
    <link rel="stylesheet" href="css/style.css">
    <link rel="stylesheet" href="css/slider.css">
    <link href="https://fonts.googleapis.com/css?family=Pacifico" rel="stylesheet">
    <!-- <meta name="viewport" content="width=device-width"> -->
</head>

<body>
    <div id="body">

        <h1 id="title"></h1>
        <br>
        <div id="author-list">
        </div>
        <br>
        <div id="affiliation-list">
        </div>
        <div id="footnote">
            <span >*equal contribution</span>
        </div>
        <br>
        <div id="conference">
        </div>
        <br>
        <div id="button-list">
            <a id="paper">
                <img src="assets/logos/arXiv.svg">
                <span>paper</span>
            </a>
            <a id="arxiv">
                <img src="assets/logos/arXiv.svg">
                <span>arXiv</span>
            </a>
            <!-- <a id="code">
                <img src="assets/logos/arXiv.svg">
                <span>code</span>
            </a> -->
        </div>
        <div id="content" style="max-width:1200px;margin:auto; margin-bottom: 1em" >
            <section class="slider-wrapper">
            <button class="slide-arrow slide-arrow-prev">
                        &#8249;
            </button>
            <button class="slide-arrow slide-arrow-next">
                        &#8250;
            </button>

                <ul class="slides-container">
                    <li class="slide">
                        <table style="margin-left:auto;margin-right:auto;">
                            <video autoplay muted loop height="300">
                                <source src="assets/teasers/joker.mp4">
                            </video>
                        </table>
                    </li>
                    <li class="slide">
                        <table style="margin-left:auto;margin-right:auto;">
                            <video autoplay muted loop height="300">
                                <source src="assets/teasers/ball.mp4">
                            </video>
                        </table>
                    </li>   
                    <li class="slide">
                        <table style="margin-left:auto;margin-right:auto;">
                            <video autoplay muted loop height="300">
                                <source src="assets/teasers/girl.mp4">
                            </video>
                        </table>
                    </li>                    
                    <li class="slide">
                        <table style="margin-left:auto;margin-right:auto;">
                            <video autoplay muted loop height="300">
                                <source src="assets/teasers/robot.mp4">
                            </video>
                        </table>
                    </li>
                    <li class="slide">
                        <table style="margin-left:auto;margin-right:auto;">
                            <video autoplay muted loop height="300">
                                <source src="assets/teasers/diver.mp4">
                            </video>
                        </table>
                    </li>
                </ul>
            </section>
            <!-- <table style="width: 100%;margin-left:auto;margin-right:auto;">
                <tr>
                    <video autoplay muted loop width="100%">
                        <source src="assets/teasers/teaser.mp4">
                    </video>
                </tr>
            </table>     -->
            <br>
            <div id='method'> 
                <h2>Abstract</h2>
                <p style="max-width:1200px; font-size:18px; margin:auto; text-align: justify; margin-bottom: 1em;">Traditional 3D content creation tools empower users to bring their imagination to life by giving them direct control over a scene's geometry, appearance, motion, and camera path. Creating computer-generated videos, however, is a tedious manual process, which can be automated by emerging text-to-video diffusion models. Despite great promise, video diffusion models are difficult to control, hindering a user to apply their own creativity rather than amplifying it. To address this challenge, we present a novel approach that combines the controllability of dynamic 3D meshes with the expressivity and editability of emerging diffusion models. For this purpose, our approach takes an animated, low-fidelity rendered mesh as input and injects the ground truth correspondence information obtained from the dynamic mesh into various stages of a pre-trained text-to-image generation model to output high-quality and temporally consistent frames. We demonstrate our approach on various examples where motion can be obtained by animating rigged assets or changing the camera path.</p>
            </div>
            <br>
            <div id='method'> 
                <h2>Method Overview</h2>
                <p style="max-width:1200px; font-size:18px; margin:auto; text-align: justify; margin-bottom: 1em;">Our system takes as input a set of UV and depths maps rendered from an animated 3D scene. We use a depth-conditioned ControlNet to generate corresponding frames while using the UV correspondences to preserve the consistency. We initialize the noise in the UV space of each object which we then render into each image. For each diffusion step, we first use extended attention for a set of keyframes and extract their pre- and post-attention features. The post-attention features are projected to the UV space and unified. Finally, all frames are generated using a weighted combination of the outputs of the extended attention with the pre-attention features of the keyframe, and the UV-composed post-attention features from the keyframes.</p>
                <img src="assets/imgs/pipeline.png" width=1200px>
            </div>
            <br>
            <div id="results">
                <h2>Gallery</h2>
                <center><p style="max-width:1500px; font-size:18px; margin:auto; text-align: justify; margin-bottom: 1em;">
                    We show a diversity of generated results below. The rendered UV map (left) is used to define the structure of the generated video clips, while a text prompt defines the style and appearance of the clips. </p></center>
                <div id="rumba">
                    <table style="width: 100%;margin-left:auto;margin-right:auto;">
                        <tr>
                            <video autoplay muted loop width="100%">
                                <source src="assets/results_combined/rumba.mp4">
                            </video>
                        </tr>
                    </table>
                </div>
                <br>
                <div id="girl">
                    <table style="width: 100%;margin-left:auto;margin-right:auto;">
                        <th>
                            <video autoplay muted loop width="100%">
                                <source src="assets/results_combined/girl.mp4">
                            </video>
                        </th>
                    </table>
                </div>
                <br>
                <div id="swimming">
                    <table style="width: 100%;margin-left:auto;margin-right:auto;">
                        <th>
                            <video autoplay muted loop width="100%">
                                <source src="assets/results_combined/swimming.mp4">
                            </video>
                        </th>
                    </table>
                </div>
                <br>
                <div id="sillydance">
                    <table style="width: 100%;margin-left:auto;margin-right:auto;">
                        <th>
                            <video autoplay muted loop width="100%">
                                <source src="assets/results_combined/silly_dance.mp4">
                            </video>
                        </th>
                    </table>
                </div>
                <br>
                <div id="three_rumba">
                    <table style="width: 100%;margin-left:auto;margin-right:auto;">
                        <th>
                            <video autoplay muted loop width="100%">
                                <source src="assets/results_combined/three_rumba.mp4">
                            </video>
                        </th>
                    </table>
                </div>
                <br>
                <div id="fox">
                    <table style="width: 100%;margin-left:auto;margin-right:auto;">
                        <th>
                            <video autoplay muted loop width="100%">
                                <source src="assets/results_combined/fox.mp4">
                            </video>
                        </th>
                    </table>
                </div>
                <br>
                <div id="ball">
                    <table style="width: 100%;margin-left:auto;margin-right:auto;">
                        <th>
                            <video autoplay muted loop width="100%">
                                <source src="assets/results_combined/ball.mp4">
                            </video>
                        </th>
                    </table>
                </div>
                <br>

                <h2>Rotations</h2>
                <center><p style="max-width:1500px; font-size:18px; margin:auto; text-align: justify; margin-bottom: 1em;">
                    Our method is able to perform static object rotations or camera rotations with constant backgrounds. </p></center>
                <div id='rotations'>    
                    <table style="width: 100%;margin-left:auto;margin-right:auto;">
                        <video autoplay muted loop width="100%">
                            <source src="assets/rotation/combined_captioned.mp4">
                        </video>
                    </table>
                </div>

                <h2>Qualitative Comparisons</h2>
                <center><p style="max-width:1500px; font-size:18px; margin:auto; text-align: justify; margin-bottom: 1em;">
                We compare with per-frame editing, adapted versions of SOTA video editing works Pix2Video and TokenFlow, and SOTA video diffusion model Gen1. </p></center>
                <div id='basketball'>    
                    <center><span style="color: #009c3b;">a basketball bouncing in a chamber under light</span></center>
                    <table style="width: 100%;margin-left:auto;margin-right:auto;">
                        <tr>
                            <video autoplay muted loop width="100%">
                                <source src="assets/qualitative_comparisons/basketball/combined_captioned.mp4">
                            </video>
                        </tr>
                    </table>
                </div>
                <br>
                <div id='fox'>    
                    <center><span style="color: #009c3b;">a Swarovski blue fox running</span></center>
                    <table style="width: 100%;margin-left:auto;margin-right:auto;">
                        <tr>
                            <video autoplay muted loop width="100%">
                                <source src="assets/qualitative_comparisons/fox/combined_captioned.mp4">
                            </video>
                        </tr>
                      </table>
                </div>
                <br>
                <!-- <h2>More Results Comparing with Gen1</h2>
                <center><p style="max-width:1500px; font-size:18px; margin:auto; text-align: justify; margin-bottom: 1em;">
                    The video-based model Gen1 achieves temporally stable results, but requires a proprietary text-to-video diffusion model that is not publicly available. Our results are competitive and only require a text-to-image model without any additional training. </p></center>
                <section class="slider-wrapper">
                <button class="slide-arrow slide-arrow-prev">
                            &#8249;
                </button>
                <button class="slide-arrow slide-arrow-next">
                            &#8250;
                </button>

                <ul class="slides-container">
                    <li class="slide">
                        <center><span style="color: #009c3b;font-family: Bradley Hand;font-size:18px;">a little girl walking around, Leonardo da Vinci style</span></center>
                        <table style="margin-left:auto;margin-right:auto;">
                            <video autoplay muted loop height="300">
                                <source src="assets/gen1_comparison/girl.mp4">
                            </video>
                        </table>
                    </li>
                    <li class="slide">
                        <center><span style="color: #009c3b;font-family: Bradley Hand;font-size:18px;">sketch of a stormtrooper dancing</span></center>
                        <table style="margin-left:auto;margin-right:auto;">
                            <video autoplay muted loop height="300">
                                <source src="assets/gen1_comparison/stormtrooper_dancing.mp4">
                            </video>
                        </table>
                    </li>
                    <li class="slide">
                        <center><span style="color: #009c3b;font-family: Bradley Hand;font-size:18px;">ball bouncing in a chamber</span></center>
                        <table style="margin-left:auto;margin-right:auto;">
                            <video autoplay muted loop height="300">
                                <source src="assets/gen1_comparison/ball.mp4">
                            </video>
                        </table>
                    </li>
                </ul>
                </section>
                <br> -->

                <p class="section">&nbsp;</p>
                <h2>Bibtex</h2>
                <table style="width: 100%;margin-left:auto;margin-right:auto;">
                    <tbody>
                        <pre style=" display: block;
                            background: #eee;
                            white-space: pre;
                            -webkit-overflow-scrolling: touch;
                            max-width: 100%;
                            min-width: 100px;
                            border-radius: 20px;
                            text-align: left;
                            overflow: hidden;
                            ">

                        @inproceedings{cai2023genren,
                            author={Cai, Shengqu and Ceylan, Duygu and Gadelha, Matheus
                                    and Huang, Chun-Hao and Wang, Tuanfeng and Wetzstein, Gordon.},
                            title={Generative Rendering: Controllable 4D-Guided Video Generation with 2D Diffusion Models},
                            booktitle={CVPR},
                            year={2024}
                        }       
                        </pre>
                    </tbody>
                </table>
            </div>
        </div>
    <script type="text/javascript" src="script.js"></script>
    </div>
</body>
